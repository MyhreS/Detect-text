{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "    IAM handwritten data has given official split of data at line level.\n",
    "    This data split is different from what we r using to train PHOSCNET.\n",
    "    \n",
    "    Below scripts finds train,test and validation data from yolov3.\n",
    "    \n",
    "    \n",
    "    flow is as below.\n",
    "    \n",
    "    1.from official line level split it identify PHOSC original train,test,valid data at word level.\n",
    "    \n",
    "    2. Once it is done for above train,test,valid data corresponding yolov3 crop counter parts are identified.\n",
    "    \n",
    "    3. These yolov3 crop counter parts are then divided into official train-test-val\n",
    "    \n",
    "    4. Create a file offIamYoloV3CropSplit.pickle which identify each yolov3 crops to its corrresponding train.test val split.\n",
    "    \n",
    "    5. This moves yolov3 crops into their respective train,test,val split. This split is according to IAM handwritten official split.\n",
    "    \n",
    "    6. This also creates a .csv script helpfull for training PHOSCNet\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    THIS PART USES data_14_april.csv for line segmwntation\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6161, 1861, 900, 940)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    THIS IS OFFICIAL SPLIT FROM IAM DATA WHICH CONTAINS SPLIT LINES.\n",
    "    \n",
    "    IDEA IS TO USE THIS LINE NAMES TO IDENTIFY CROP BELONGS TO WHICH LINE.\n",
    "    \n",
    "    THE FILE data_14_.csv contains co-ordinate as well as the crop name from .xml file\n",
    "    \n",
    "    use this crop name to derive line no eg. g06-031n-04-05 here line no is 04 and word \n",
    "    \n",
    "    no is 05. so removing last -05 and using remaining g06-031n-04 can let us know where it belong\n",
    "    \n",
    "    i.e. train,test,validation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "basePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/\"\n",
    "\n",
    "csvpath=basePath+\"/dataset/data_14_april.csv\"\n",
    "imgPath=\"./data/dataset/forms/\"\n",
    "\n",
    "\n",
    "basePath2=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/\"\n",
    "offTrainSplit=basePath2+\"/newFilterData/largeWriterIndependentTextLineRecognitionTask/trainset.txt\"\n",
    "\n",
    "offVal1Split=basePath2+\"/newFilterData/largeWriterIndependentTextLineRecognitionTask/validationset1.txt\"\n",
    "offVal2Split=basePath2+\"/newFilterData/largeWriterIndependentTextLineRecognitionTask/validationset2.txt\"\n",
    "\n",
    "offTestSplit=basePath2+\"/newFilterData/largeWriterIndependentTextLineRecognitionTask/testset.txt\"\n",
    "\n",
    "with open(offTrainSplit) as f:\n",
    "    trainFiles=f.read().splitlines()\n",
    "\n",
    "with open(offTestSplit) as f:\n",
    "    testFiles=f.read().splitlines()\n",
    "\n",
    "with open(offVal1Split) as f:\n",
    "    valFiles1=f.read().splitlines()\n",
    "\n",
    "with open(offVal2Split) as f:\n",
    "    valFiles2=f.read().splitlines()\n",
    "\n",
    "    \n",
    "len(trainFiles),len(testFiles),len(valFiles1),len(valFiles2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataframe shape: (115187, 14) Index(['image_name', 'class', 'width', 'height', 'org_x1', 'org_y1', 'org_x2',\n",
      "       'org_y2', 'text', 'cropName', 'x', 'y', 'w', 'h'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(csvpath)\n",
    "print(\" Dataframe shape:\",df.shape,df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " indx: 0  trainCount: 0  valCount: 0  valCount2: 0  testCount: 0  line: 1  notFound: 1\n",
      " \n",
      " indx: 10000  trainCount: 5285  valCount: 645  valCount2: 885  testCount: 931  line: 1171  notFound: 2255\n",
      " \n",
      " indx: 20000  trainCount: 9314  valCount: 1776  valCount2: 1693  testCount: 2517  line: 2328  notFound: 4701\n",
      " \n",
      " indx: 30000  trainCount: 13711  valCount: 2413  valCount2: 2305  testCount: 4698  line: 3478  notFound: 6874\n",
      " \n",
      " indx: 40000  trainCount: 18902  valCount: 3011  valCount2: 2691  testCount: 6269  line: 4615  notFound: 9128\n",
      " \n",
      " indx: 50000  trainCount: 23859  valCount: 3521  valCount2: 3462  testCount: 7553  line: 5813  notFound: 11606\n",
      " \n",
      " indx: 60000  trainCount: 27941  valCount: 3996  valCount2: 4454  testCount: 9172  line: 6997  notFound: 14438\n",
      " \n",
      " indx: 70000  trainCount: 32372  valCount: 4737  valCount2: 5262  testCount: 10766  line: 8142  notFound: 16864\n",
      " \n",
      " indx: 80000  trainCount: 37073  valCount: 5363  valCount2: 6355  testCount: 12305  line: 9269  notFound: 18905\n",
      " \n",
      " indx: 90000  trainCount: 42079  valCount: 6202  valCount2: 6739  testCount: 13632  line: 10416  notFound: 21349\n",
      " \n",
      " indx: 100000  trainCount: 46288  valCount: 6895  valCount2: 7594  testCount: 15237  line: 11568  notFound: 23987\n",
      " \n",
      " indx: 110000  trainCount: 51094  valCount: 7842  valCount2: 7886  testCount: 16952  line: 12755  notFound: 26227\n",
      " 1.total: 115187\n",
      " 2.total: 115187\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    below part classify actual training data into IAM handwritten official split\n",
    "\"\"\"\n",
    "\n",
    "trainCount,testCount,valCount1,valCount2,notFound=0,0,0,0,0\n",
    "trainCrops,val1Crops,val2Crops,testCrops,notCrops=[],[],[],[],[]\n",
    "lineNames=[]\n",
    "\n",
    "for indx,row in df.iterrows():\n",
    "    \n",
    "    cropName=row.cropName    \n",
    "    lineName=cropName[:-3]\n",
    "    \n",
    "    #print(\" cropName:\",cropName,\" lineName=\",lineName)\n",
    "\n",
    "    lineNames.append(lineName)\n",
    "    \n",
    "    if lineName in trainFiles:\n",
    "        trainCount+=1\n",
    "        trainCrops.append(lineName)\n",
    "    elif lineName in valFiles1:\n",
    "        valCount1+=1\n",
    "        val1Crops.append(lineName)\n",
    "        \n",
    "    elif lineName in valFiles2:\n",
    "        valCount2+=1\n",
    "        val2Crops.append(lineName)\n",
    "    elif lineName in testFiles:\n",
    "        testCount+=1\n",
    "        testCrops.append(lineName)\n",
    "    else:\n",
    "        notFound+=1\n",
    "        notCrops.append(lineName)\n",
    "        #print(\" \\n indx:\",indx,\" notFound:\",notFound,\" cropName=\",cropName,\"lineName=\",lineName,\" text:\",row.text)\n",
    "        #input(\" check!!!\")\n",
    "        \n",
    "    if indx%10000==0:\n",
    "        print(\" \\n indx:\",indx,\" trainCount:\",trainCount,\" valCount:\",valCount1,\" valCount2:\",valCount2,\" testCount:\",testCount,\" line:\",len(set(lineNames)),\" notFound:\",notFound)\n",
    "\n",
    "print(\" 1.total:\",trainCount+valCount1+valCount2+testCount+notFound)\n",
    "\n",
    "trainCrops,val1Crops,val2Crops,testCrops,notCrops=list(set(trainCrops)),list(set(val1Crops)),list(set(val2Crops)),list(set(testCrops)),list(set(notCrops))\n",
    "\n",
    "print(\" 2.total:\",trainCount+valCount1+valCount2+testCount+notFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e01-062-07',\n",
       " 'l07-172-05',\n",
       " 'l04-062-02',\n",
       " 'j06-030-08',\n",
       " 'h04-071-02',\n",
       " 'b04-181-07',\n",
       " 'g06-050j-09',\n",
       " 'h06-000-00',\n",
       " 'h06-085-09',\n",
       " 'g06-045n-06']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFiles[0:5]\n",
    "\n",
    "print(len(trainCrops)+len(val1Crops)+len(val2Crops)+len(testCrops)+len(notCrops))\n",
    "len(notCrops)\n",
    "notCrops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67595, 7617, 9125)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    yolov3 localised data crops\n",
    "    goal is to identify official split at word level\n",
    "\"\"\"\n",
    "cropBase=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData/\"\n",
    "\n",
    "cropsYoloTrainPath=cropBase+\"cropsYoloV3Train//\"\n",
    "cropsYoloValPath=cropBase+\"cropsYoloV3valid//\"\n",
    "cropsYoloTestPath=cropBase+\"cropsYoloV3Test//\"\n",
    "\n",
    "cropsYoloTrain=os.listdir(cropsYoloTrainPath)\n",
    "cropsYoloVal=os.listdir(cropsYoloValPath)\n",
    "cropsYoloTest=os.listdir(cropsYoloTestPath)\n",
    "\n",
    "len(cropsYoloTrain),len(cropsYoloTest),len(cropsYoloVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84337"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropsYoloTrain+cropsYoloVal+cropsYoloTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    identify overlapping area \n",
    "\"\"\"\n",
    "\n",
    "def area(a, b):  # returns None if rectangles don't intersect\n",
    "    dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin)\n",
    "    dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        return dx*dy\n",
    "\n",
    "from collections import namedtuple,defaultdict\n",
    "Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')\n",
    "\n",
    "d=defaultdict(list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    BELOW DICTIONARY d CONTAINS YOLOV3 CROP NAME AND VALUE IS CORRESPONDING\n",
    "    LINE NUMBER, IDEA IS TO USE THIS LINE NUMBER TO IDENTIFY WHERE YOLOV3 CROPS BELONG \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indx: 0  imgName: n06-148.png_45_[753, 2208, 836, 2234]_as_.png  orgImgName: n06-148.png  temp: (93, 14)  cord= [753, 2208, 836, 2234]  type: <class 'list'>\n",
      " keys: 1\n",
      " indx: 5000  imgName: g03-049.png_6_[671, 1247, 893, 1329]_Noel_.png  orgImgName: g03-049.png  temp: (62, 14)  cord= [671, 1247, 893, 1329]  type: <class 'list'>\n",
      " keys: 4929\n",
      " indx: 10000  imgName: f01-135.png_81_[313, 2172, 585, 2248]_usually_.png  orgImgName: f01-135.png  temp: (57, 14)  cord= [313, 2172, 585, 2248]  type: <class 'list'>\n",
      " keys: 9851\n",
      " indx: 15000  imgName: k07-134.png_84_[1059, 1745, 1283, 1831]_when_.png  orgImgName: k07-134.png  temp: (66, 14)  cord= [1059, 1745, 1283, 1831]  type: <class 'list'>\n",
      " keys: 14771\n",
      " indx: 20000  imgName: j04-012.png_36_[1808, 1628, 2158, 1687]_chemical_.png  orgImgName: j04-012.png  temp: (68, 14)  cord= [1808, 1628, 2158, 1687]  type: <class 'list'>\n",
      " keys: 19697\n",
      " indx: 25000  imgName: k07-063a.png_69_[905, 1572, 1024, 1641]_that_.png  orgImgName: k07-063a.png  temp: (70, 14)  cord= [905, 1572, 1024, 1641]  type: <class 'list'>\n",
      " keys: 24614\n",
      " indx: 30000  imgName: l04-106.png_40_[1868, 1301, 2134, 1334]_customers_.png  orgImgName: l04-106.png  temp: (81, 14)  cord= [1868, 1301, 2134, 1334]  type: <class 'list'>\n",
      " keys: 29530\n",
      " indx: 35000  imgName: m06-106.png_71_[523, 1328, 678, 1381]_Haris_.png  orgImgName: m06-106.png  temp: (92, 14)  cord= [523, 1328, 678, 1381]  type: <class 'list'>\n",
      " keys: 34459\n",
      " indx: 40000  imgName: r02-013.png_98_[378, 1448, 724, 1534]_lected_.png  orgImgName: r02-013.png  temp: (83, 14)  cord= [378, 1448, 724, 1534]  type: <class 'list'>\n",
      " keys: 39381\n",
      " indx: 45000  imgName: k04-106.png_9_[2098, 1513, 2197, 1565]_an_.png  orgImgName: k04-106.png  temp: (66, 14)  cord= [2098, 1513, 2197, 1565]  type: <class 'list'>\n",
      " keys: 44307\n",
      " indx: 50000  imgName: g06-031d.png_46_[453, 1275, 621, 1317]_cannot_.png  orgImgName: g06-031d.png  temp: (85, 14)  cord= [453, 1275, 621, 1317]  type: <class 'list'>\n",
      " keys: 49230\n",
      " indx: 55000  imgName: h02-022.png_77_[1796, 1830, 2103, 1897]_sufficient_.png  orgImgName: h02-022.png  temp: (81, 14)  cord= [1796, 1830, 2103, 1897]  type: <class 'list'>\n",
      " keys: 54152\n",
      " indx: 60000  imgName: b04-134.png_78_[328, 908, 667, 1038]_prosperity_.png  orgImgName: b04-134.png  temp: (84, 14)  cord= [328, 908, 667, 1038]  type: <class 'list'>\n",
      " keys: 59079\n",
      " indx: 65000  imgName: p02-131.png_5_[1613, 932, 1784, 968]_come_.png  orgImgName: p02-131.png  temp: (75, 14)  cord= [1613, 932, 1784, 968]  type: <class 'list'>\n",
      " keys: 64003\n",
      " indx: 70000  imgName: p01-168.png_70_[1195, 1118, 1381, 1185]_kind_.png  orgImgName: p01-168.png  temp: (77, 14)  cord= [1195, 1118, 1381, 1185]  type: <class 'list'>\n",
      " keys: 68922\n",
      " indx: 75000  imgName: j04-012.png_67_[618, 2351, 731, 2411]_for_.png  orgImgName: j04-012.png  temp: (68, 14)  cord= [618, 2351, 731, 2411]  type: <class 'list'>\n",
      " keys: 73852\n",
      " indx: 80000  imgName: g06-031h.png_77_[1085, 1286, 1226, 1383]_fear_.png  orgImgName: g06-031h.png  temp: (85, 14)  cord= [1085, 1286, 1226, 1383]  type: <class 'list'>\n",
      " keys: 78775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for indx,imgName in enumerate(cropsYoloTrain+cropsYoloVal+cropsYoloTest):\n",
    "    \n",
    "    if \".csv\" in imgName:\n",
    "        continue\n",
    "    \n",
    "    orgImgName=imgName.split(\".png\")[0]+\".png\"\n",
    "    temp=df[df[\"image_name\"]==orgImgName]\n",
    "    \n",
    "    #print(\" indx:\",indx,\" imgName:\",imgName,\" orgImgName:\",orgImgName,\" temp:\",temp.shape,\" cord=\",cord,\" type:\",type(cord))\n",
    "\n",
    "    cord=imgName.split(\"_[\")[1].split(\"]_\")[0]\n",
    "    cord=eval(\"[\"+cord+\"]\")\n",
    "    \n",
    "    x1,y1,x2,y2=cord[0],cord[1],cord[2],cord[3]\n",
    "    \n",
    "    ra = Rectangle(x1, y1, x2, y2)\n",
    "    \n",
    "    for rowNo,row in temp.iterrows():\n",
    "        orgX1,orgX2=row.org_x1,row.org_x2\n",
    "        orgY1,orgY2=row.org_y1,row.org_y2\n",
    "        \n",
    "        rb = Rectangle(orgX1, orgY1, orgX2, orgY2)\n",
    "            \n",
    "        if area(ra, rb):\n",
    "            \n",
    "            d[imgName].append(row.cropName[:-3])# row.text\n",
    "            \n",
    "    if indx%5000==0:\n",
    "        \n",
    "        print(\" indx:\",indx,\" imgName:\",imgName,\" orgImgName:\",orgImgName,\" temp:\",temp.shape,\" cord=\",cord,\" type:\",type(cord))\n",
    "\n",
    "        print(\" keys:\",len(d.keys()))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCrops,val1Crops,val2Crops,testCrops,notCrops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    IDENTIFY WHERE YOLOV3 CROPS BELONG\n",
    "    \n",
    "    and create a dictionary which tells where each yoloV3 crop belong.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainData,val1Data,val2Data,testData,noData=[],[],[],[],[]\n",
    "\n",
    "for key in d.keys():\n",
    "    \n",
    "    offlineName=d[key][0]\n",
    "    \n",
    "    if offlineName in trainCrops:\n",
    "        d[key].append(\"train\")\n",
    "        trainData.append(key)\n",
    "    elif offlineName in val1Crops:\n",
    "        d[key].append(\"val1\")\n",
    "        val1Data.append(key)\n",
    "    elif offlineName in val2Crops:\n",
    "        d[key].append(\"val2\")\n",
    "        val2Data.append(key)        \n",
    "    elif offlineName in testCrops:\n",
    "        d[key].append(\"test\")\n",
    "        testData.append(key)        \n",
    "    elif offlineName in notCrops:\n",
    "        d[key].append(\"not\")\n",
    "        noData.append(key)    \n",
    "    \n",
    "    \n",
    "print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38892, 5851, 6309, 12559, 19421)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData),len(val1Data),len(val2Data),len(testData),len(noData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#a = {'hello': 'world'}\n",
    "\n",
    "dictDumpPath=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData//\"\n",
    "\n",
    "with open(dictDumpPath+'offIamYoloV3CropSplit.pickle', 'wb') as handle:\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(dictDumpPath+'offIamYoloV3CropSplit.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    \n",
    "print(d == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cropBase=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData/\"\n",
    "\n",
    "cropsYoloTrainPath=cropBase+\"cropsYoloV3Train//\"\n",
    "cropsYoloValPath=cropBase+\"cropsYoloV3valid//\"\n",
    "cropsYoloTestPath=cropBase+\"cropsYoloV3Test//\"\n",
    "\n",
    "cropsYoloTrain=os.listdir(cropsYoloTrainPath)\n",
    "cropsYoloVal=os.listdir(cropsYoloValPath)\n",
    "cropsYoloTest=os.listdir(cropsYoloTestPath)\n",
    "\n",
    "len(cropsYoloTrain),len(cropsYoloTest),len(cropsYoloVal)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cropNo: 0  counts 1   0   0 5852\n",
      " cropNo: 1000  counts 1001   0   0 6852\n",
      " cropNo: 2000  counts 2001   0   0 7852\n",
      " cropNo: 3000  counts 3001   0   0 8852\n",
      " cropNo: 4000  counts 4001   0   0 9852\n",
      " cropNo: 5000  counts 5001   0   0 10852\n",
      " cropNo: 6000  counts 5045   681   275 11852\n",
      " trainCount 5045  valCount: 681  testCount: 583\n"
     ]
    }
   ],
   "source": [
    "from shutil import copy2\n",
    "\n",
    "cropBase=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData/\"\n",
    "cropBase2=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/\"\n",
    "\n",
    "toPath=\"\"\n",
    "fromPath=\"\"\n",
    "trainCropCount,valCropCount,testCropCount=0,0,0,\n",
    "\n",
    "\n",
    "for cropNo,imgCropName in enumerate(val2Data):\n",
    "        \n",
    "    if imgCropName in cropsYoloTrain:\n",
    "            fromPath=os.path.join(cropBase,\"cropsYoloV3Train\",imgCropName)\n",
    "        #toPath=os.path.join(cropBase2,\"cropsYoloV3Train\")\n",
    "        trainCropCount+=1\n",
    "        \n",
    "        \n",
    "    elif imgCropName in cropsYoloVal:\n",
    "        fromPath=os.path.join(cropBase,\"cropsYoloV3valid\",imgCropName)\n",
    "        #toPath=os.path.join(cropBase2,\"cropsYoloV3valid\")\n",
    "        valCropCount+=1\n",
    "        \n",
    "    elif imgCropName in cropsYoloTest:\n",
    "        fromPath=os.path.join(cropBase,\"cropsYoloV3Test\",imgCropName)\n",
    "        #toPath=os.path.join(cropBase2,\"cropsYoloV3Test\")\n",
    "        testCropCount+=1\n",
    "\n",
    "    toPath=os.path.join(cropBase2,\"cropsYoloV3valid\")\n",
    "    \n",
    "    copy2(fromPath,toPath)\n",
    "    \n",
    "    if cropNo%1000==0:\n",
    "        print(\" cropNo:\",cropNo,\" counts\",trainCropCount,\" \",valCropCount,\" \",testCropCount,len(os.listdir(toPath)))\n",
    "\n",
    "    \n",
    "        \n",
    "print(\" trainCount\",trainCropCount,\" valCount:\",valCropCount,\" testCount:\",testCropCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38892, 67595, 12559)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData),len(cropsYoloTrain),len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    create .csv file : IAM_trainYoloCropsAug.csv, IAM_testYoloCrops.csv,  IAM_valYoloCrops.csv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indx: 0  total images: 233352\n",
      " indx: 5000  total images: 233352\n",
      " indx: 10000  total images: 233352\n",
      " indx: 15000  total images: 233352\n",
      " indx: 20000  total images: 233352\n",
      " indx: 25000  total images: 233352\n",
      " indx: 30000  total images: 233352\n",
      " indx: 35000  total images: 233352\n",
      " indx: 40000  total images: 233352\n",
      " indx: 45000  total images: 233352\n",
      " indx: 50000  total images: 233352\n",
      " indx: 55000  total images: 233352\n",
      " indx: 60000  total images: 233352\n",
      " indx: 65000  total images: 233352\n",
      " indx: 70000  total images: 233352\n",
      " indx: 75000  total images: 233352\n",
      " indx: 80000  total images: 233352\n",
      " indx: 85000  total images: 233352\n",
      " indx: 90000  total images: 233352\n",
      " indx: 95000  total images: 233352\n",
      " indx: 100000  total images: 233352\n",
      " indx: 105000  total images: 233352\n",
      " indx: 110000  total images: 233352\n",
      " indx: 115000  total images: 233352\n",
      " indx: 120000  total images: 233352\n",
      " indx: 125000  total images: 233352\n",
      " indx: 130000  total images: 233352\n",
      " indx: 135000  total images: 233352\n",
      " indx: 140000  total images: 233352\n",
      " indx: 145000  total images: 233352\n",
      " indx: 150000  total images: 233352\n",
      " indx: 155000  total images: 233352\n",
      " indx: 160000  total images: 233352\n",
      " indx: 165000  total images: 233352\n",
      " indx: 170000  total images: 233352\n",
      " indx: 175000  total images: 233352\n",
      " indx: 180000  total images: 233352\n",
      " indx: 185000  total images: 233352\n",
      " indx: 190000  total images: 233352\n",
      " indx: 195000  total images: 233352\n",
      " indx: 200000  total images: 233352\n",
      " indx: 205000  total images: 233352\n",
      " indx: 210000  total images: 233352\n",
      " indx: 215000  total images: 233352\n",
      " indx: 220000  total images: 233352\n",
      " indx: 225000  total images: 233352\n",
      " indx: 230000  total images: 233352\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "#regex.sub('', 'ab3d*E')\n",
    "\n",
    "cropBase2=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/\"\n",
    "\n",
    "df=pd.DataFrame(columns=[\"Image\",\"Word\",\"Writer\"])\n",
    "\n",
    "\n",
    "folderName=[\"cropYolov3TrainOrigAug\",\"cropYolov3TrainAug\",\"cropsYoloV3valid\",\"cropsYoloV3Test\"]\n",
    "fileName=[\"IAM_trainYoloCropsOrigAug.csv\",\"IAM_trainYoloCropsAug.csv\",\"IAM_valYoloCrops.csv\",\"IAM_testYoloCrops.csv\"]\n",
    "\n",
    "indx=0\n",
    "src=os.path.join(cropBase2,folderName[indx])\n",
    "csvDest=os.path.join(cropBase2,fileName[indx])\n",
    "\n",
    "allImgCrops=os.listdir(src)\n",
    "\n",
    "for indx,cropName in enumerate(allImgCrops):\n",
    "    \n",
    "    if indx%5000==0:\n",
    "        print(\" indx:\",indx,\" total images:\",len(allImgCrops))\n",
    "        df.to_csv(csvDest,index=False)\n",
    "    \n",
    "    word=cropName.split(\"]_\")[1].split(\"_\")[0]\n",
    "    \n",
    "    \n",
    "    word=regex.sub('',word)\n",
    "\n",
    "    #print(\" cropName:\",cropName,\" text=\",text)\n",
    "    \n",
    "    if len(word):\n",
    "\n",
    "        df.loc[indx,\"Image\"]=cropName\n",
    "        df.loc[indx,\"Word\"]=word\n",
    "        df.loc[indx,\"Writer\"]=\"\"\n",
    "        \"\"\"\n",
    "        if indx==10:\n",
    "            break\n",
    "        \"\"\"\n",
    "        \n",
    "df.to_csv(csvDest,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12093, 3), 12093, Index(['Image', 'Word', 'Writer'], dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,len(allImgCrops),df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indx: 0\n",
      " indx: 5000\n",
      " indx: 10000\n",
      " Delete count: 14\n"
     ]
    }
   ],
   "source": [
    "df.shape,len(allImgCrops),df.columns\n",
    "imgList=df[\"Image\"].to_list()\n",
    "delCount=0\n",
    "\n",
    "for indx, cropName in enumerate(allImgCrops):\n",
    "    \n",
    "    if indx%5000==0:\n",
    "        print(\" indx:\",indx)\n",
    "    \n",
    "    if not cropName in imgList:\n",
    "        os.remove(src+\"//\"+cropName)\n",
    "        delCount+=1\n",
    "print(\" Delete count:\",delCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/cropYolov3TrainAug'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Word</th>\n",
       "      <th>Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a04-043.png_30_[786, 1482, 957, 1523]_main_2_.png</td>\n",
       "      <td>main</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g06-026f.png_6_[1861, 747, 1915, 787]_an_11_.png</td>\n",
       "      <td>an</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e04-103.png_96_[462, 908, 665, 1034]_plank_2_.png</td>\n",
       "      <td>plank</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g06-050a.png_4_[766, 1069, 828, 1133]_he_1_.png</td>\n",
       "      <td>he</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h04-025.png_70_[601, 1794, 652, 1864]_the_3_.png</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image   Word Writer\n",
       "0  a04-043.png_30_[786, 1482, 957, 1523]_main_2_.png   main       \n",
       "1   g06-026f.png_6_[1861, 747, 1915, 787]_an_11_.png     an       \n",
       "2  e04-103.png_96_[462, 908, 665, 1034]_plank_2_.png  plank       \n",
       "3    g06-050a.png_4_[766, 1069, 828, 1133]_he_1_.png     he       \n",
       "4   h04-025.png_70_[601, 1794, 652, 1864]_the_3_.png    the       "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = float(\"nan\")\n",
    "print(f\"It's np.isnan  : {np.isnan(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as npprint(f\"It's np.isnan  : {np.isnan(x)}\")\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 0\n"
     ]
    }
   ],
   "source": [
    "word=\"1-\"\n",
    "word=str(regex.sub('',word))\n",
    "print(\"word:\",len(word))\n",
    "\n",
    "if(word != word):\n",
    "\tprint(\"it's a nan value\")\n",
    "#print(f\"It's np.isnan  : {np.isnan(word)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233352"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "img=os.listdir(\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/cropYolov3TrainOrigAug\")\n",
    "\n",
    "\n",
    "len(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231864, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/IAM_trainYoloCropsOrigAug.csv\")\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/data/newFilterData2/IAM_trainYoloCropsOrigAug.csv\")\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Word</th>\n",
       "      <th>Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e01-050.png_72_[547, 1835, 668, 1908]_time__1_...</td>\n",
       "      <td>time</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e04-019.png_70_[1760, 1649, 1911, 1739]_then__...</td>\n",
       "      <td>then</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b05-045.png_108_[1192, 1067, 1282, 1144]_he__5...</td>\n",
       "      <td>he</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b01-027.png_87_[1757, 928, 1984, 1009]_duke's_...</td>\n",
       "      <td>dukes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c04-035.png_42_[942, 1450, 1041, 1535]_the__3_...</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image   Word  Writer\n",
       "0  e01-050.png_72_[547, 1835, 668, 1908]_time__1_...   time     NaN\n",
       "1  e04-019.png_70_[1760, 1649, 1911, 1739]_then__...   then     NaN\n",
       "2  b05-045.png_108_[1192, 1067, 1282, 1144]_he__5...     he     NaN\n",
       "3  b01-027.png_87_[1757, 928, 1984, 1009]_duke's_...  dukes     NaN\n",
       "4  c04-035.png_42_[942, 1450, 1041, 1535]_the__3_...    the     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(columns=[\"names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineNumber=0\n",
    "\n",
    "def load_annotations(annot_path):\n",
    "    final_annotations = []\n",
    "    with open(annot_path, 'r') as f:\n",
    "        txt = f.read().splitlines()\n",
    "        annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
    "\n",
    "    for lineNumber,annotation in enumerate(annotations):\n",
    "        # fully parse annotations\n",
    "        line = annotation.split()\n",
    "        image_path, index = \"\", 1\n",
    "        for i, one_line in enumerate(line):\n",
    "            if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                if image_path != \"\": image_path += \" \"\n",
    "                image_path += one_line\n",
    "            else:\n",
    "                index = i\n",
    "                break\n",
    "        \n",
    "        imageName=image_path.split(\"forms/\")[1]\n",
    "        \n",
    "        df.loc[lineNumber,\"names\"]=imageName\n",
    "        final_annotations.append(imageName)\n",
    "    return final_annotations\n",
    "\n",
    "annot_path=\"/home/aniketag/pred/mnist_test_PhoscIamOfficialSplitForYoloLineLevel1.txt\"\n",
    "load_annotations(annot_path)\n",
    "\n",
    "df.to_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3_simula/YOLO/testFiles.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: pip: not found\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_keras2",
   "language": "python",
   "name": "yolo_keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
